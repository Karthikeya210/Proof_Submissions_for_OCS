{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOO8fZiRfEPhezEkzp4sM5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikeya210/Proof_Submissions_for_OCS/blob/main/SpeechandSentimentRecog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-rebjvZkChv",
        "outputId": "82ea747c-0ef8-4016-b549-c66ad08c0b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-367aebaa1829>:7: DtypeWarning: Columns (1,2,3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('alphabets_28x28.csv', nrows=100000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 785)\n",
            "Epoch 1/10\n",
            "624/624 [==============================] - 8s 6ms/step - loss: 0.5374 - accuracy: 0.9382 - val_loss: 0.0661 - val_accuracy: 0.9800\n",
            "Epoch 2/10\n",
            "624/624 [==============================] - 4s 7ms/step - loss: 0.0496 - accuracy: 0.9857 - val_loss: 0.0521 - val_accuracy: 0.9850\n",
            "Epoch 3/10\n",
            "624/624 [==============================] - 5s 7ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0407 - val_accuracy: 0.9891\n",
            "Epoch 4/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.0482 - val_accuracy: 0.9868\n",
            "Epoch 5/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0464 - val_accuracy: 0.9887\n",
            "Epoch 6/10\n",
            "624/624 [==============================] - 4s 6ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.0547 - val_accuracy: 0.9877\n",
            "Epoch 7/10\n",
            "624/624 [==============================] - 5s 7ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0537 - val_accuracy: 0.9879\n",
            "Epoch 8/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0865 - val_accuracy: 0.9819\n",
            "Epoch 9/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0508 - val_accuracy: 0.9891\n",
            "Epoch 10/10\n",
            "624/624 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0566 - val_accuracy: 0.9881\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784c5c15f7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('alphabets_28x28.csv', nrows=100000)\n",
        "print(df.shape)\n",
        "df = df.dropna()\n",
        "sentiment_data = pd.read_csv('sentiment_analysis_dataset.csv')\n",
        "\n",
        "X = df.iloc[:, 1:].values.astype(np.float32)\n",
        "y = df.iloc[:, 0].values.astype(str)\n",
        "\n",
        "X = X.reshape(X.shape[0], 28, 28)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y, num_classes=26)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "ocr_model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "ocr_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ocr_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18mwxfyAwbgI",
        "outputId": "f366eb17-4e12-413b-a964-ae3bf7beee57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "data = pd.read_csv('sentiment_analysis_dataset.csv')\n",
        "\n",
        "stopset = stopwords.words('english')\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)\n",
        "\n",
        "X = data.line\n",
        "y = data.sentiment\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred_proba = clf.predict_proba(X_test_vec)\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
        "print(f'ROC AUC Score: {roc_auc:.2f}')\n",
        "\n",
        "y_pred = clf.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "random_sentence = \"I am so happy to be a core member of Epoch\"\n",
        "\n",
        "random_sentence_vec = vectorizer.transform([random_sentence])\n",
        "\n",
        "predicted_sentiment = clf.predict(random_sentence_vec)[0]\n",
        "\n",
        "print(f\"Random Sentence: {random_sentence}\")\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDJZU4zvw_K1",
        "outputId": "f3989d0f-2705-4365-e03b-2d16b5f36822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 0.97\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       1.00      0.50      0.67         2\n",
            "       Happy       0.40      1.00      0.57         2\n",
            "     Neutral       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.62         8\n",
            "   macro avg       0.80      0.67      0.63         8\n",
            "weighted avg       0.85      0.62      0.64         8\n",
            "\n",
            "Random Sentence: I am so happy to be a core member of Epoch\n",
            "Predicted Sentiment: Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "import pytesseract\n",
        "import cv2\n",
        "from PIL import Image\n",
        "def preprocess_and_ocr(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    text = pytesseract.image_to_string(gray)\n",
        "    return text\n",
        "\n",
        "image_path = 'line_4.png'\n",
        "\n",
        "\n",
        "extracted_text = preprocess_and_ocr(image_path)\n",
        "\n",
        "random_sentence = extracted_text\n",
        "random_sentence_vec = vectorizer.transform([random_sentence])\n",
        "predicted_sentiment = clf.predict(random_sentence_vec)[0]\n",
        "\n",
        "# Print results\n",
        "print(f\"Random Sentence: {random_sentence}\")\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTFEBPck0gQu",
        "outputId": "b1a30957-9880-4df0-dd6c-596925361129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentence: 20 ee CA\n",
            "Ae BN eS Dek ee\n",
            "i oe eo]\n",
            "St ee ee OA\n",
            "\n",
            "cn ee, Pas\n",
            "A en tk)\n",
            "MIITHYERIDIE WY\n",
            "TINY Ae a OS\n",
            "a a er\n",
            "ene rs any\n",
            "\f\n",
            "Predicted Sentiment: Angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nw4qf_qGFRs-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}